import feedparser
import json
from datetime import datetime
import requests
from bs4 import BeautifulSoup

# ================== 1. L·∫§Y TIN T·ª®C T·ª™ RSS ==================
def fetch_news():
    RSS_URL = "https://vnexpress.net/rss/tin-moi-nhat.rss"
    feed = feedparser.parse(RSS_URL)

    news_items = []
    for entry in feed.entries[:5]:
        news_items.append({
            "id": entry.get("id", entry.link),
            "title": entry.title,
            "link": entry.link,
            "pubDate": entry.get("published", ""),
            "description": entry.get("summary", ""),
            "image": ""
        })

    output_data = {
        "source": "VnExpress RSS",
        "updated": datetime.utcnow().isoformat() + "Z",
        "articles": news_items,
        "total_articles": len(news_items)
    }

    with open("news.json", "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    print("‚úÖ ƒê√£ t·∫°o news.json v·ªõi", len(news_items), "tin t·ª©c.")

# ================== 2. L·∫§Y GI√Å V√ÄNG T·ª™ WEB ==================
def fetch_gold_price():
    GOLD_URL = "https://giavang.net/bang-gia-vang-trong-nuoc"
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(GOLD_URL, timeout=15, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        gold_data = []
        
        # 1. T√¨m T·∫§T C·∫¢ c√°c b·∫£ng trong trang
        all_tables = soup.find_all('table')
        print(f"üîç T√¨m th·∫•y {len(all_tables)} b·∫£ng tr√™n trang.")

        for table_index, table in enumerate(all_tables):
            # 2. T√¨m t·∫•t c·∫£ h√†ng <tr> trong b·∫£ng hi·ªán t·∫°i
            rows = table.find_all('tr')
            
            # 3. L·ªçc v√† x·ª≠ l√Ω t·ª´ng h√†ng c√≥ d·ªØ li·ªáu (c√≥ thu·ªôc t√≠nh data-code)
            for row in rows:
                # B·ªè qua c√°c h√†ng tr·ªëng, h√†ng ti√™u ƒë·ªÅ, h√†ng qu·∫£ng c√°o
                if row.get('data-code') and row.get('data-code') != 'data-title':
                    # T√¨m t·∫•t c·∫£ √¥ <td> ho·∫∑c <th> trong h√†ng
                    cols = row.find_all(['td', 'th'])
                    
                    # Ch·ªâ x·ª≠ l√Ω h√†ng c√≥ ƒë·ªß d·ªØ li·ªáu (√≠t nh·∫•t 4 c·ªôt)
                    if len(cols) >= 4:
                        # L·∫•y vƒÉn b·∫£n t·ª´ c√°c c·ªôt, lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
                        col_texts = [col.get_text(strip=True) for col in cols]
                        
                        gold_data.append({
                            "ma": row.get('data-code', ''),  # M√£ s·∫£n ph·∫©m, v√≠ d·ª•: SJL1L10
                            "loai_vang": col_texts[0],       # C·ªôt 1: Lo·∫°i v√†ng (vd: SJC 1L 10L)
                            "ham_luong": col_texts[1],       # C·ªôt 2: H√†m l∆∞·ª£ng
                            "mua_vao": col_texts[2],         # C·ªôt 3: Gi√° mua v√†o
                            "ban_ra": col_texts[3]           # C·ªôt 4: Gi√° b√°n ra
                        })
                        print(f"   ‚ûï ƒê√£ th√™m: {col_texts[0]} - Mua: {col_texts[2]}, B√°n: {col_texts[3]}")

        # 4. ƒê√≥ng g√≥i v√† ghi file JSON
        gold_output = {
            "source": "GiaVang.net",
            "updated": datetime.utcnow().isoformat() + "Z",
            "data": gold_data,
            "total_items": len(gold_data)
        }

        with open("giavang.json", "w", encoding="utf-8") as f:
            json.dump(gold_output, f, ensure_ascii=False, indent=2)
            
        print(f"‚úÖ ƒê√£ t·∫°o giavang.json v·ªõi {len(gold_data)} m·ª•c gi√° v√†ng.")
        
    except requests.RequestException as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi: {e}")
    except Exception as e:
        print(f"‚ùå L·ªói x·ª≠ l√Ω: {e}")
# ================== 3. CH·∫†Y CH√çNH ==================
if __name__ == "__main__":
    fetch_news()
    fetch_gold_price()
    print("‚ú® Ho√†n t·∫•t t·∫•t c·∫£ c√¥ng vi·ªác!")
